# from langchain.llms import LlamaCpp

# # Initialize the LLaMA model
# llm = LlamaCpp(model_path="path_to_your_llama_model.gguf")

# # Test query
# query = "What is AI?"
# response = llm(query)
# print(response)
